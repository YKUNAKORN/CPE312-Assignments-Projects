{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdaa883e-fd90-46dc-b1bd-4de8c53ecca0",
   "metadata": {},
   "source": [
    "## [CPE312] Group Assignment\n",
    "## การสกัดและวิเคราะห์ข้อมูลหนังสือจาก \"Books to Scrape\"\n",
    "ร้านขายหนังสือออนไลน์สตาร์ทอัพต้องการเลือกสต็อกหนังสือที่มีแนวโน้มขายดีตามแนวโน้มของตลาดในปัจจุบัน เป้าหมายคือการเพิ่มผลตอบแทนจากการลงทุนเบื้องต้น โดยเน้นหนังสือที่ได้รับความนิยมและมีราคาแข่งขันได้\n",
    "<p>วัตถุประสงค์:</p>\n",
    "\n",
    "1. ให้นิสิตจับกลุ่ม กลุ่มละ3-4 คน \n",
    "2. เพื่อค้นหาประเภทหนังสือที่ได้รับความนิยมมากที่สุดตามการจัดอันดับและบทวิจารณ์จากลูกค้า\n",
    "3. เพื่อดู\tแนวโน้มราคาของหนังสือในแต่ละประเภทและเปรียบเทียบกับราคาเฉลี่ยของตลา\n",
    "4. เพื่อค้นหา.\tรูปแารของหนังสือทมีความี่ต้องการสในท้องตลาด ูงเพื่อให้ร้านมีความเข้าตลาดสำหรับในการจัดสต็หนังสืออกใหม่ในคราวถัดไป\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a69e676-bf17-4db4-a151-dddfdf5add44",
   "metadata": {},
   "source": [
    "### กรอบประเด็นปัญหา\n",
    "\n",
    "เพื่อตัดสินใจว่าควรสต็อกหนังสือหมวดใดบ้าง โดยบริษัทต้องการข้อมูลเชิงลึกเกี่ยวกับแนวโน้มราคาหนังสือปัจจุบัน ความชอบของลูกค้า และข้อเสนอที่แข่งขันกัน อย่างไรก็ตาม พวกเขาขาดข้อมูลที่จำเป็นในการตัดสินใจเหล่านี้"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06405ca-3fc2-4817-8653-a3eed4f08940",
   "metadata": {},
   "source": [
    "### Business Questions\n",
    "\n",
    "1. ประเภทหนังสือใดมีการจัดอันดับเฉลี่ยและรีวิวจากลูกค้าสูงที่สุด? โดยข้อมูลนี้จะช่วยในการเข้าใจความชอบและความต้องการของลูกค้า\n",
    "2. \tราคาหนังสือแตกต่างกันอย่างไรในแต่ละประเภท และมีแนวโน้มราคาเป็นอย่างไรตามช่วงเวลา?โดย ข้อมูลนี้จำเป็นสำหรับการกำหนดกลยุทธ์การตั้งราคาที่แข่งขันได\n",
    "3. •\tหนังสือเล่มใดที่มักจะหมดสต็อกบ่อยครั้ง และสิ่งนี้บ่งบอกอะไรเกี่ยวกับความนิยมหรือปัญหาด้านอุปท (ความต้องการขายสินค้าของผู้ผลิต)าน? ข้อมูลเกี่ยวกับรูปแบบสต็อกสามารถช่วยในการจัดการสต็อกได้อย่างมีประสิทธิภาพ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d607807-19ee-46f8-b6a0-a966b6413c7e",
   "metadata": {},
   "source": [
    "## Example code to create csv file of all products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e84292c-11e3-45ca-8433-865948bf2495",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bs4'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# import web grabbing client and\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# HTML parser\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m urlopen \u001b[38;5;28;01mas\u001b[39;00m uReq\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbs4\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BeautifulSoup \u001b[38;5;28;01mas\u001b[39;00m soup\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# variable to store website link as string\u001b[39;00m\n\u001b[1;32m      7\u001b[0m myurl \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp://books.toscrape.com/index.html\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bs4'"
     ]
    }
   ],
   "source": [
    "# import web grabbing client and\n",
    "# HTML parser\n",
    "from urllib.request import urlopen as uReq\n",
    "from bs4 import BeautifulSoup as soup\n",
    " \n",
    "# variable to store website link as string\n",
    "myurl = 'http://books.toscrape.com/index.html'\n",
    " \n",
    "# grab website and store in variable uclient\n",
    "uClient = uReq(myurl)\n",
    " \n",
    "# read and close HTML\n",
    "page_html = uClient.read()\n",
    "uClient.close()\n",
    " \n",
    "# call BeautifulSoup for parsing\n",
    "page_soup = soup(page_html, \"html.parser\")\n",
    " \n",
    "# grabs all the products under list tag\n",
    "bookshelf = page_soup.findAll(\n",
    "    \"li\", {\"class\": \"col-xs-6 col-sm-4 col-md-3 col-lg-3\"})\n",
    " \n",
    "# create csv file of all products\n",
    "filename = (\"Books.csv\")\n",
    "f = open(filename, \"w\")\n",
    " \n",
    "headers = \"Book title, Price\\n\"\n",
    "f.write(headers)\n",
    " \n",
    "for books in bookshelf:\n",
    " \n",
    "    # collect title of all books\n",
    "    book_title = books.h3.a[\"title\"]\n",
    " \n",
    "    # collect book price of all books\n",
    "    book_price = books.findAll(\"p\", {\"class\": \"price_color\"})\n",
    "    price = book_price[0].text.strip()\n",
    " \n",
    "    print(\"Title of the book :\" + book_title)\n",
    "    print(\"Price of the book :\" + price)\n",
    " \n",
    "    f.write(book_title + \",\" + price+\"\\n\")\n",
    " \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983d4f7a-6a9b-42d7-912f-008aaa8aaa21",
   "metadata": {},
   "source": [
    "## Example Code to Extract Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076fbfa8-983a-4480-804a-35e5080a255b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://books.toscrape.com'\n",
    "html = urlopen(url)\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Assuming categories are listed in a sidebar or specific section\n",
    "category_container = soup.find('div', {'class': 'side_categories'})\n",
    "categories = category_container.find_all('a')\n",
    "\n",
    "for category in categories:\n",
    "    category_name = category.get_text().strip()\n",
    "    category_link = url + category['href']\n",
    "    print(category_name, category_link)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acb7071-35e9-42ba-950c-87a5dbce9289",
   "metadata": {},
   "source": [
    "## Example Code to Extract Links to Detail Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557a6b6e-1168-4c4c-a6d4-8554e54ab7eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen as uReq\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from urllib.parse import urljoin  # Import the urljoin function\n",
    "\n",
    "# Correct the base URL to the root of the book listings\n",
    "base_url = 'https://books.toscrape.com/catalogue/category/books_1/index.html'\n",
    "\n",
    "# Open connection and grab the main page\n",
    "uClient = uReq(base_url)\n",
    "page_html = uClient.read()\n",
    "uClient.close()\n",
    "\n",
    "# HTML parsing\n",
    "page_soup = soup(page_html, \"html.parser\")\n",
    "\n",
    "# Find the correct link by inspecting where the relative links start\n",
    "book_links = [urljoin(base_url, x.find('a')['href']) for x in page_soup.findAll(\"h3\")]\n",
    "\n",
    "# Print the correctly formed URLs\n",
    "print(\"Extracted links:\", book_links)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b4f1f3-09ac-4011-acca-e1f0c32896ac",
   "metadata": {},
   "source": [
    "## Example Code to Scrape Detailed Information from Each Book's Detail Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e42f56-b1de-4e0e-a805-2b6485387701",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize DataFrame to store book data\n",
    "books_df = pd.DataFrame(columns=[\"Title\", \"Product Type\", \"Price excl. tax\", \"Price incl. tax\"])\n",
    "\n",
    "# Loop through each collected book link to access detail pages\n",
    "for link in book_links:\n",
    "    print(link)\n",
    "    uClient = uReq(link)\n",
    "    detail_html = uClient.read()\n",
    "    uClient.close()\n",
    "\n",
    "    # HTML parsing for detail page\n",
    "    detail_soup = soup(detail_html, \"html.parser\")\n",
    "\n",
    "    # Extracting detailed product information\n",
    "    title = detail_soup.h1.text\n",
    "    product_info = {row.th.text: row.td.text for row in detail_soup.findAll(\"tr\")}\n",
    "    \n",
    "    # Create a new DataFrame for the current book's data\n",
    "    new_row = pd.DataFrame([{\n",
    "        \"Title\": title,\n",
    "        \"Product Type\": product_info.get(\"Product Type\"),\n",
    "        \"Price excl. tax\": product_info.get(\"Price (excl. tax)\"),\n",
    "        \"Price incl. tax\": product_info.get(\"Price (incl. tax)\")\n",
    "       \n",
    "    }])\n",
    "\n",
    "    # Append the new row to the DataFrame\n",
    "    books_df = pd.concat([books_df, new_row], ignore_index=True)\n",
    "\n",
    "print(books_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34882aa-292f-4f32-9b83-2d74df211b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
